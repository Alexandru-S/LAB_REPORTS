% !TeX spellcheck = en_US
\documentclass{article}


\usepackage{lipsum}
\usepackage[margin=1in,includefoot]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[english]{babel}
\usepackage{subcaption}

\usepackage{booktabs}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{listings}


% Header and Footer Stuff
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}




\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\lstset{
 language=C++,
 aboveskip=3mm,
 belowskip=3mm,
 showstringspaces=false,
 columns=flexible,
 basicstyle={\small\ttfamily},
 numbers=none,
 numberstyle=\tiny\color{gray},
 keywordstyle=\color{blue},
 commentstyle=\color{dkgreen},
 stringstyle=\color{mauve},
 breaklines=true,
 breakatwhitespace=true,
 tabsize=3
}




\begin{document}


\begin{titlepage}
	\begin{center}
	\begin{align*}
	\includegraphics[height=1.75in]{logo.png}
	\end{align*}




	
	\line(1,0){300}\\
	[0.25in]
	\huge{\bfseries Door Detection}\\
	[2mm]
	\line(1,0){200}\\
	[1.5cm]
	\textsc{\LARGE Assignment 2}\\
	[0.75cm]
	\textsc{\Large CS4053 Computer Vision}\\
	[7cm]	
	\end{center}
	
	
	
	\begin{flushright}
	\textsc{\large Alexandru Sulea\\
	D Stream\\
	\#12315152\\
	13 December 2016\\}
	\end{flushright}
	
\end{titlepage}
%Table of Contents Stuff%
\tableofcontents
%\listoffigures
%\addcontentsline{toc}{section}{List of Figures}
\listoftables
\addcontentsline{toc}{section}{List of Tables}




\thispagestyle{empty}
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}


\pagebreak
\section{RED PIXEL DETECTION}
\subsection{Intro}\label{sec:intro}
The following lab was based on the procedure of determining when a door is opened and closed in a room given that there is a person walking through the door and that the light in the scene can vary depending on the lighting conditions in the room but also from the light propagating from other sources.\\
The lab was thus conducted with the objective of detecting a door and identifying when said door closes and opens with respect to time as defined in frames.\\

\begin{lstlisting}




\end{lstlisting}
\subsection{Procedure}\label{sec:intro}
Taking notes of what was discussed and shown in class together with the theory and description on the official Open CV page, the following procedure was planned out. 
The scene itself consists of two distinct parts. The first being a man walking from foreground to background and back, the second being that a door opens and closes at arbitrary intervals. The person in the picture serves no real purpose for this lab other than to induce uncertainty of when the door opens and closes. Thus the first operation is to perform a background subtraction on the person and have them removed as much as possible from the scene. This will not only allow us to see the door more clearly, but it will also help clean up the frames and make Hough Lines more accurate later on.\\


Once the person is removed from the picture, the door detection must begin.\\ Here a number of already built in Open CV procedures can be used such as HoughLines() , HoughLineP() or Line Segment Detector. Although LSD is somewhat more accurate then HoughLineP(), the later is also more easily customizable and faster to process. Given how door frame tracking throughout every video frame was not the objective and only opening and closing, HoughLineP() was chosen to help with the door detection. \\
Here whatever lines were detected in the scene by HoughlinesP(), only the lines that were horizontal or vertical, given 10 degrees of error were accepted as the true vertical and horizontal lines.\\
After the horizontal and vertical lines were filtered through, their determinate is calculated and compared to all the other vertical or horizontal lines as to check if the lines form a box at any point. Should the lines intersect, a circle is drawn at the intersection points.\\
Then a diagonal line is searched for, its point calculated as well as its determinate. Should the diagonal line intersect one of the points where the horizontal and vertical lines intersect, then this is assumed to top side of the door opening, thus creating an angled line.\\ 

The steps for  creating the solution were as follows:\\

The video file is first loaded in to MOG2 which is a background subtraction method, MOG2 was used over MOG due to MOG2 being more adaptable to changing light conditions and also to covering more of the subject with the mask.\\
A bit_wise not is then performed on the mask so as to turn it into a foreground subtraction method. This way anything that moves in the foreground is made invisible while the background is largely unaffected The learning rate for the method was chosen at 0.005 . This was found to have the perfect balance between making the subject invisible, while at the same time keeping the moving door as part of the background.\\




\begin{figure}[H]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.5\linewidth, height=5cm]{prof_color.png} 
\caption{unaltered image}
\label{fig:subim1}
\end{subfigure}

\caption{Figure of normal color frame}
\label{fig:image2}
\end{figure}

\begin{lstlisting}
			pMOG2->apply(frame_vid_N, fgMaskMOG2, 0.005);
bitwise_not(fgMaskMOG2, fgMaskMOG2);
absdiff(frame_vid_N, fgMaskMOG2, vid_ands);
//imshow("wvvb", vid_ands);
\end{lstlisting}

Following this procedure, the image was ready to be converted to be able to accept HoughLinesP(). To produce the desired lines, the image was converted to gray scale, so as to be easier to perform adaptive thresholding Adaptive thresholding was chosen due to its adaptability in varying light conditions. A binary picture was then received which needed to be blurred somewhat to regain some of the lost line continuity. The picture was now ready to be inserted into canny for border detection and then converted back to BGR so as to be able to be combined with other images.

\begin{lstlisting}
cvtColor(frame_vid_N, frame_grey, CV_BGR2GRAY);
adaptiveThreshold(frame_grey, frame_g_tresh, 75, ADAPTIVE_THRESH_GAUSSIAN_C, CV_THRESH_BINARY, 13, 4);
GaussianBlur(frame_g_tresh, frame_blur, Size(5, 5), 1, 1, 1);
Canny(frame_blur, dst, 50, 200, 3);
cvtColor(dst, cdst, COLOR_GRAY2BGR);

\end{lstlisting}



\begin{figure}[H]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=2cm\linewidth, height=4cm]{door_mask.PNG} 
\caption{MOG2}
\label{fig:subim1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}

\includegraphics[width=0.5\linewidth, height=5cm]{door_neg_mask.PNG}
\caption{bitwise not MOG2 }
\label{fig:subim2}
\end{subfigure}
\caption{transition}
\label{fig:image2}
\end{figure}

\begin{figure}[H]
\center
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.5\linewidth, height=5cm]{door_back_proj.PNG} 
\caption{given result of MOG2}
\label{fig:subim1}
\end{subfigure}
\caption{foreground is now transparent}
\label{fig:image2}
\end{figure}


\begin{lstlisting}
	HoughLinesP(dst, lines4, 1, CV_PI / 180, 80+60, 50, 50);
	int vert_line_count = 0;
	int hor_line_count = 0;
	
\end{lstlisting}


\begin{figure}[H]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.5\linewidth, height=5cm]{door_closed_h_v.PNG} 
\caption{video 2 door houghlinesp}
\label{fig:subim1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.5\linewidth, height=5cm]{door2_h_v.PNG}
\caption{video 1 door houghlinesp}
\label{fig:subim2}
\end{subfigure}
\caption{houghlinep}
\label{fig:image2}
\end{figure}


The rest of the code has to do with simple detection of houghlines given their angles. Thus only the horizontal , vertical and in specific cases, diagonal lines are stored. The code below shows how this was achieved. All code was sourced from basic calculus with the exception of the intersection algorithm which was taken from an opencv online tutorial.

\begin{lstlisting}
for (size_t i = 0; i < lines4.size(); i++)
{
Vec4i l = lines4[i];
/*get angle of line*/
double angle = atan2(l[3] - l[1], l[2] - l[0]) * 180 / CV_PI;
/*horizontal lines*/
if (angle <5 && angle >= -5 || angle <-175 && angle >= 175)
{
hor_line_count++;
h_l.push_back(l);
//cout << "HORIZONTAL LINES " <<Point(l[0],l[1])<<Point(l[2],l[3]) <<endl;
line(cdst, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(0, 0, 255), 3, CV_AA);
}
/*vertical lines */
if (angle< 95 && angle >= 85 || angle < -85 && angle >= -95)
{
vert_line_count++;
v_l.push_back(l);
//cout << "VERTICAL LINES " << Point(l[0], l[1]) << Point(l[2], l[3]) << endl;
line(cdst, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(255, 0, 0), 3, CV_AA);		
}
/*if door not closed*/
if (angle <-5 && angle >= -25 || angle <175 && angle >= 150 || angle >-175 && angle <= -150)
{
if (frame_thresh > frame_count - last_frame) {
open_close_count++;
oc_l.push_back(l);
//cout << "DIAGONAL LINES " << Point(l[0], l[1]) << Point(l[2], l[3]) << "FRAME " << frame_count << endl;
}
else {
last_frame = frame_count;
diag_line_count++;
diag_l.push_back(l);
line(cdst, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(0, 200,200), 3, CV_AA);
if (diag_line_count % 2 == 0) {
cout << "Door Closes on points " << Point(l[0], l[1]) << Point(l[2], l[3]) << " at FRAME " << frame_count << endl;
}
else {
cout << "Door Opens on points " << Point(l[0], l[1]) << Point(l[2], l[3]) << " at FRAME " << frame_count << endl;
}
}}}
/*Draw circle at line intersection*/
for (int i = 0; i < h_l.size(); i++)
{
for (int j = 0; j < v_l.size(); j++)
{
Point poi = intersection(Point(h_l[i][0], h_l[i][1]), Point(h_l[i][2], h_l[i][3]), Point(v_l[j][0], v_l[j][1]), Point(v_l[j][2], v_l[j][3]));
circle(cdst, poi, 6, Scalar(0, 255, 0),  5,  8,0);
}}
for (int i = 0; i < h_l.size(); i++)
{
for (int j = 0; j < oc_l.size(); j++)
{
Point poi = intersection(Point(h_l[i][0], h_l[i][1]), Point(h_l[i][2], h_l[i][3]), Point(oc_l[j][0], oc_l[j][1]), Point(oc_l[j][2], oc_l[j][3]));
if ( (Point(h_l[i][0], h_l[i][1]) == Point(oc_l[j][0], oc_l[j][1])) || (Point(h_l[i][2], h_l[i][3]) == Point(oc_l[j][2], oc_l[j][3])) || (Point(h_l[i][2], h_l[i][3]) == Point(oc_l[j][0], oc_l[j][1])) || (Point(h_l[i][0], h_l[i][1]) == Point(oc_l[j][2], oc_l[j][3])) )
{
line(cdst, Point(oc_l[i][0], oc_l[i][1]), Point(oc_l[i][2], oc_l[j][3]), Scalar(0, 200, 200), 3, CV_AA);
circle(cdst, poi, 6, Scalar(200, 0, 200), 5, 8, 0);
}}}

\end{lstlisting}
%\includegraphics[height=2in,width=5in]{}
%\includegraphics[height=2in,width=5in]{}




\subsection{Performance}\label{sec:intro}
Given as how the ground truth was provided or this lab in terms of door frame position and opening and closing frames, it was quite simple to compare the achieved results to the ground truth. \\





\begin{figure}[H]
\center
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=4cm]{door1_score.PNG} 
\caption{}
\label{fig:subim2}
\end{subfigure}
\caption{Tdoor1 score}
\label{fig:image2}
\end{figure}


\begin{figure}[H]
	\center
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=0.9\linewidth, height=4cm]{Door2_score.PNG} 
		\caption{}
		\label{fig:subim2}
	\end{subfigure}
	\caption{Tdoor2 score}
	\label{fig:image2}
\end{figure}


\begin{figure}[H]
	\center
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=0.9\linewidth, height=4cm]{door3_score.PNG} 
		\caption{}
		\label{fig:subim2}
	\end{subfigure}
	\caption{Tdoor1 score}
	\label{fig:image2}
\end{figure}


\begin{figure}[H]
	\center
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=0.9\linewidth, height=4cm]{door4_score.PNG} 
		\caption{}
		\label{fig:subim2}
	\end{subfigure}
	\caption{Tdoor2 score}
	\label{fig:image2}
\end{figure}

\subsection{Discussion}\label{sec:intro}
While solving the problems inherent in detecting a door, a number of problems arose. The main being that, even though the solution was designed to fit a wide array of cases, it will fail in many more due to a variety of problems such as:

\begin{enumerate}
	\item The precision and accuracy of the solution is heavily dependent of the lighting conditions present and also the color difference of the door as opposed to its background.\\ While doing the lab, algorithms continually had problems detecting where the door ended and the door frame ended, due to the fact that the two were very flush and of the same design and color.
	\item The door shape itself would need to have 4 corners to provide an accurate door representation, any lift doors or star trek/ star wars type doors would not be detected. 
	
	\item The next group of problems arise once the video is recorded of a viable door opening and closing Assuming that the door conforms to the standard door dimensions and that the video angle is not skewed then the question of lighting comes into effect. Too much or little light, such as when a powerful lamp is turned on or when the lights are off can seriously effect the accuracy of the algorithm. One option to offset this issue is to use infra red enabled cameras so as to get a more light independent picture.
	
	\item Even if a door is detected, the continual detection of the door will depend on a clear line of sight from the camera to the door and also a preferably higher definition image for improved accuracy. People or objects existing between the camera and door line of sight can seriously hamper the accuracy. Thus to mitigate this effect, a back projection algorithm is generally advised.
	
	
\end{enumerate}


The problems outlined above are just the general outline. There are many more problems which may be case specific. In manual doors for example, a door opening or closing at an uneven rate can also decrease the accuracy and precision of the door detection.\\
Lastly there are the accuracy errors which were due to false positives and false negatives in the video.\\
The false positives were mostly due to noise in the original video, which through thresholding and canny promulgated in the HoughLines video. This was easy to fix by adjusting the thresholding of the video to a value at which there was a minimum amount of error but still enough detail for lines to be drawn.\\
Light reflectance was found to be a major cause of the earliest false positives. As the door is not mat but glossy. This property combined with light shining directly on the door cause the door to somewhat reflect the objects in front of it but behind the camera. Giving the impression that the door may be moving, when in fact it is static.


The false negatives were somewhat harder to solve as important details in the video may be lost through canny. Thus a line that existed and was clearly defined in the color, unaltered version of the video may have dissipated. This can be somewhat corrected by extending or merging lines in the HoughLinesP() function, although this does not work for all cases. \\

Lastly, the solution presented does not solve for all cases. One example may be that if a door is continuously rocked back and forth. Such as in a busy hallway where someone may hold the door for many other people. The algorithm will see the back and forth movement of the door as opening and closing. As there is no state of a door being opened. Only that a door is about to be opened or about to eb closed.\\









\pagebreak
\end{document}


